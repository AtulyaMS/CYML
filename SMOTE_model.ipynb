{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtulyaMS/CYML/blob/main/SMOTE_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbCN-w1aUj94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Set numpy to print only 2 decimal digits for neatness\n",
        "np.set_printoptions(precision=2, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "2rPGl0vRUsp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-plot"
      ],
      "metadata": {
        "id": "lPdcy_cN1CBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict, train_test_split\n",
        "import scikitplot as skplt\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "NPE1Dzrz048u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (78, 110, 86)\n",
        "IMG_2D_SHAPE = (IMG_SHAPE[1] * 4, IMG_SHAPE[2] * 4)\n",
        "#SHUFFLE_BUFFER = 5 #Subject to change\n",
        "N_CLASSES = 3"
      ],
      "metadata": {
        "id": "SCkmXYk4UwSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "53gLkErKUyQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/gdrive/MyDrive/\"\n",
        "base_dir = root_dir + 'Final_model_training'\n",
        "os.chdir(base_dir)"
      ],
      "metadata": {
        "id": "CGUeTqQjVP09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_img(itk_image, out_spacing=[2.0, 2.0, 2.0]):\n",
        "    ''' This function resamples images to 2-mm isotropic voxels.\n",
        "      \n",
        "        Parameters:\n",
        "            itk_image -- Image in simpleitk format, not a numpy array\n",
        "            out_spacing -- Space representation of each voxel\n",
        "            \n",
        "        Returns: \n",
        "            Resulting image in simpleitk format, not a numpy array\n",
        "    '''\n",
        "    \n",
        "    # Resample images to 2mm spacing with SimpleITK\n",
        "    original_spacing = itk_image.GetSpacing()\n",
        "    original_size = itk_image.GetSize()\n",
        "\n",
        "    out_size = [\n",
        "        int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\n",
        "        int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\n",
        "        int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\n",
        "\n",
        "    resample = sitk.ResampleImageFilter()\n",
        "    resample.SetOutputSpacing(out_spacing)\n",
        "    resample.SetSize(out_size)\n",
        "    resample.SetOutputDirection(itk_image.GetDirection())\n",
        "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
        "    resample.SetTransform(sitk.Transform())\n",
        "    resample.SetDefaultPixelValue(itk_image.GetPixelIDValue())\n",
        "\n",
        "    resample.SetInterpolator(sitk.sitkBSpline)\n",
        "\n",
        "    return resample.Execute(itk_image)"
      ],
      "metadata": {
        "id": "9uD3AUgUVSGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def registrate(sitk_fixed, sitk_moving, bspline=False):\n",
        "    ''' Perform image registration using SimpleElastix.\n",
        "        By default, uses affine transformation.\n",
        "        \n",
        "        Parameters:\n",
        "            sitk_fixed -- Reference atlas (sitk .nii)\n",
        "            sitk_moving -- Image to be registrated\n",
        "                           (sitk .nii)\n",
        "            bspline -- Whether or not to perform non-rigid\n",
        "                       registration. Note: it usually deforms\n",
        "                       the images and increases execution times\n",
        "    '''\n",
        "    \n",
        "    elastixImageFilter = sitk.ElastixImageFilter()#sitk.ElastixImageFilter()   SimpleElastix()\n",
        "    elastixImageFilter.SetFixedImage(sitk_fixed)\n",
        "    elastixImageFilter.SetMovingImage(sitk_moving)\n",
        "\n",
        "    parameterMapVector = sitk.VectorOfParameterMap()\n",
        "    parameterMapVector.append(sitk.GetDefaultParameterMap(\"affine\"))\n",
        "    if bspline:\n",
        "        parameterMapVector.append(sitk.GetDefaultParameterMap(\"bspline\"))\n",
        "    elastixImageFilter.SetParameterMap(parameterMapVector)\n",
        "\n",
        "    elastixImageFilter.Execute()\n",
        "    return elastixImageFilter.GetResultImage()"
      ],
      "metadata": {
        "id": "lWkqMWxwVUOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def skull_strip_nii(original_img, destination_img, frac=0.2): #\n",
        "    ''' Practice skull stripping on the given image, and save\n",
        "        the result to a new .nii image.\n",
        "        Uses FSL-BET \n",
        "        (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide#Main_bet2_options:)\n",
        "        \n",
        "        Parameters:\n",
        "            original_img -- Original nii image\n",
        "            destination_img -- The new skull-stripped image\n",
        "            frac -- Fractional intensity threshold for BET\n",
        "    '''\n",
        "    \n",
        "    btr = fsl.BET()\n",
        "    btr.inputs.in_file = original_img\n",
        "    btr.inputs.frac = frac\n",
        "    btr.inputs.out_file = destination_img\n",
        "    btr.cmdline\n",
        "    res = btr.run()\n",
        "    return res"
      ],
      "metadata": {
        "id": "FxTUOobGcLbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slices_matrix_2D(img):\n",
        "  ''' Transform a 3D MRI image into a 2D image, by obtaining 9 slices \n",
        "      and placing them in a 4x4 two-dimensional grid.\n",
        "      \n",
        "      All 16 cuts are from a horizontal/axial view. They are selected\n",
        "      from the 30th to the 60th level of the original 3D image.\n",
        "      \n",
        "      Parameters:\n",
        "        img -- np.ndarray with the 3D image\n",
        "        \n",
        "      Returns:\n",
        "        np.ndarray -- The resulting 2D image\n",
        "  '''\n",
        "  \n",
        "  # create the final 2D image \n",
        "  image_2D = np.empty(IMG_2D_SHAPE)\n",
        "  \n",
        "  # set the limits and the step\n",
        "  TOP = 60\n",
        "  BOTTOM = 30\n",
        "  STEP = 2\n",
        "  N_CUTS = 16\n",
        "  \n",
        "  # iterator for the cuts\n",
        "  cut_it = TOP\n",
        "  # iterator for the rows of the 2D final image\n",
        "  row_it = 0\n",
        "  # iterator for the columns of the 2D final image\n",
        "  col_it = 0\n",
        "  \n",
        "  for cutting_time in range(N_CUTS):\n",
        "    \n",
        "    # cut\n",
        "    cut = img[cut_it, :, :]\n",
        "    cut_it -= STEP\n",
        "    \n",
        "    # reset the row iterator and move the\n",
        "    # col iterator when needed\n",
        "    if cutting_time in [4, 8, 12]:\n",
        "      row_it = 0\n",
        "      col_it += cut.shape[1]\n",
        "    \n",
        "    # copy the cut to the 2D image\n",
        "    for i in range(cut.shape[0]):\n",
        "      for j in range(cut.shape[1]):\n",
        "        image_2D[i + row_it, j + col_it] = cut[i, j]\n",
        "    row_it += cut.shape[0]\n",
        "  \n",
        "  # return the final 2D image, with 3 channels\n",
        "  # this is necessary for working with most pre-trained nets\n",
        "  return np.repeat(image_2D[None, ...], 3, axis=0).T"
      ],
      "metadata": {
        "id": "Q-V9xevkcMPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_2D(abs_path): #, labels\n",
        "  ''' Load an image (.nii) and its label, from its absolute path.\n",
        "      Transform it into a 2D image, by obtaining 16 slices and placing them\n",
        "      in a 4x4 two-dimensional grid.\n",
        "      \n",
        "      Parameters:\n",
        "        abs_path -- Absolute path, filename included\n",
        "        labels -- Label mapper\n",
        "        \n",
        "      Returns:\n",
        "        img -- The .nii image, converted into a numpy array\n",
        "        label -- The label of the image (from argument 'labels')\n",
        "        \n",
        "  '''\n",
        "  \n",
        "  # obtain the label from the path (it is the last directory name)\n",
        "  #label = labels[abs_path.split('/')[-2]]\n",
        "  \n",
        "  # load the image with SimpleITK\n",
        "  sitk_image = sitk.ReadImage(abs_path)\n",
        "  \n",
        "  # transform into a numpy array\n",
        "  img = sitk.GetArrayFromImage(sitk_image)\n",
        "  \n",
        "  # apply whitening\n",
        "  img = preprocessing.whitening(img)\n",
        "  \n",
        "  # make the 2D image\n",
        "  img = slices_matrix_2D(img)\n",
        "  \n",
        "  return img"
      ],
      "metadata": {
        "id": "2_zSCHJJcO36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gz_extract(zipfile):\n",
        "    file_name = (os.path.basename(zipfile)).rsplit('.',1)[0] #get file name for file within\n",
        "    with gzip.open(zipfile,\"rb\") as f_in, open(f\"{zipfile.split('/')[0]}/{file_name}\",\"wb\") as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "    os.remove(zipfile) # delete zipped file\n",
        "    # return f\"{zipfile.split('/')[0]}/{file_name}\""
      ],
      "metadata": {
        "id": "Z800M7-lcREh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
        "        value = value.numpy() # get value of tensor\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array"
      ],
      "metadata": {
        "id": "KTbxjd69cTFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_tfrecords(x, y, filename):\n",
        "    writer = tf.io.TFRecordWriter(filename)\n",
        "\n",
        "    for image, label in zip(x, y):\n",
        "        example = tf.train.Example(features=tf.train.Features(\n",
        "            feature={\n",
        "                'image': _bytes_feature(serialize_array(image)), #tf.train.Feature(bytes_list=tf.train.BytesList(value=[image.tobytes()])),\n",
        "                'label': _int64_feature(label) #tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
        "            }))\n",
        "        writer.write(example.SerializeToString())\n"
      ],
      "metadata": {
        "id": "Y_0cj_XXcVMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _parse_image_function(example_proto):\n",
        "    image_feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "    image = tf.io.parse_tensor(features['image'], out_type=tf.double) #tf.io.decode_raw(features['image'], tf.float32) \n",
        "   # image.set_shape([3 * 344 * 440])\n",
        "    image = tf.reshape(image, [344, 440, 3])\n",
        "\n",
        "    label = tf.cast(features['label'], tf.int32)\n",
        "    label = tf.one_hot(features['label'], 3)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "CS2Crpp7cbci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(epochs, batch_size, filename):\n",
        "\n",
        "    # filenames = [os.path.join(channel, channel_name + '.tfrecords')]\n",
        "    dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "    dataset = dataset.prefetch(batch_size)                      ##4\n",
        "    dataset = dataset.repeat(epochs)                            ##2\n",
        "    dataset = dataset.shuffle(buffer_size=10 * batch_size)      ##1\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)    ##3\n",
        "\n",
        "\n",
        "    # dataset = dataset.map(_parse_image_function, num_parallel_calls=10)\n",
        "    # dataset = dataset.shuffle(buffer_size=10 * batch_size)               ##1\n",
        "    # dataset = dataset.repeat(epochs)                                     ##2\n",
        "    # dataset = dataset.batch(batch_size, drop_remainder=True)             ##3\n",
        "    # dataset = dataset.prefetch(batch_size)                               ##4\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "3HWd2y27ccLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lb2H6iI5llv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['CN', 'MCI', 'AD']\n",
        "category_dict = {'CN':0, 'MCI':1, 'AD':2}\n",
        "nifti_files = []\n",
        "labels = []\n",
        "\n",
        "newpath = f\"./Nifti_files/\"\n",
        "for category in categories:\n",
        "    path = f\"./{category}/\"   \n",
        "# r=root, d=directories, f = files\n",
        "    for r, d, f in os.walk(path):\n",
        "        for file in f:\n",
        "            if '.nii' in file:\n",
        "                nifti_files.append(os.path.join(r, file))\n",
        "                label = category_dict[category]#0 if category=='CN' else 1 if category=='MCI' else 2\n",
        "                labels.append(label)\n",
        "                \n",
        "print(nifti_files[0:5])\n",
        "print(labels[0:5])"
      ],
      "metadata": {
        "id": "KpvLAVnfc3JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atlas = sitk.ReadImage('average305_t1_tal_lin_mask.nii')\n",
        "atlas = resample_img(atlas)"
      ],
      "metadata": {
        "id": "hU6zOVn6c34r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in nifti_files:\n",
        "    sitk_image = sitk.ReadImage(image)\n",
        "# transform into a numpy array\n",
        "    sitk_array = sitk.GetArrayFromImage(sitk_image)\n",
        "    \n",
        "    res_image = resample_img(sitk_image)\n",
        "    res_array = sitk.GetArrayFromImage(res_image)\n",
        "    res_array = preprocessing.resize_image_with_crop_or_pad(res_array, img_size=(128, 192, 192), mode='symmetric')\n",
        "    res_array = preprocessing.whitening(res_array)\n",
        "    \n",
        "    registrated_image = registrate(atlas, res_image, bspline=False)\n",
        "    sitk.WriteImage(registrated_image, f\"Registrated/{image.split('/')[-1]}_registrated.nii\")\n",
        "    \n",
        "    registrated_image = sitk.ReadImage(f\"Registrated/{image.split('/')[-1]}_registrated.nii\")\n",
        "    registrated_array = sitk.GetArrayFromImage(registrated_image)\n",
        "    \n",
        "    skull_strip_nii(f\"Registrated/{image.split('/')[-1]}_registrated.nii\", f\"Skull_Stripped/{image.split('/')[-1]}_stripped.nii\", frac=0.2)\n",
        "    gz_extract(f\"Skull_Stripped/{image.split('/')[-1]}_stripped.nii.gz\")"
      ],
      "metadata": {
        "id": "RY_SYWZLc57y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss_images = os.listdir('Skull_Stripped')\n",
        "\n",
        "for image in ss_images:\n",
        "    image_2d = load_image_2D(f\"Skull_Stripped/{image}\")\n",
        " #   print(image_2d.shape)\n",
        "    np.save(f\"Image_2d/{image.split('/')[-1]}_2d\", image_2d)"
      ],
      "metadata": {
        "id": "KATdDjd0c9W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_array = []\n",
        "label_array = []\n",
        "train_array = [\"CN_TRAIN_Image2D\", \"MCI_TRAIN_Image2D\", \"AD_TRAIN_Image2D\"]\n",
        "\n",
        "for folder in train_array:\n",
        "  for filename in os.listdir(folder):\n",
        "    if filename.endswith('.npy'):\n",
        "      image_array.append(np.load(f\"{folder}/{filename}\")) \n",
        "      label_array.append(0 if 'CN' in folder else 1 if 'MCI' in folder else 2)\n",
        "        \n",
        "image_array = np.array(image_array)"
      ],
      "metadata": {
        "id": "a4PLcRdAc_Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_array.shape)\n",
        "print(Counter(label_array).keys()) # equals to list(set(words))\n",
        "print(Counter(label_array).values()) # counts the elements' frequency"
      ],
      "metadata": {
        "id": "gp-SjAo2dCih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Over-sampling: SMOTE\n",
        "#SMOTE (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, \n",
        "#based on those that already exist. It works randomly picking a point from the minority class and computing \n",
        "#the k-nearest neighbors for this point.The synthetic points are added between the chosen point and its neighbors.\n",
        "#We'll use ratio='minority' to resample the minority class.\n",
        "smote = SMOTE('minority')\n",
        "\n",
        "image_array_sm, label_array_sm = smote.fit_resample(image_array.reshape((image_array.shape[0], image_array.shape[1]*image_array.shape[2]*image_array.shape[3])), label_array)"
      ],
      "metadata": {
        "id": "781Tgnd1m-es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_array_smarr, label_array_smarr = np.array(image_array_sm), np.array(label_array_sm)\n",
        "image_array_smarr = image_array_smarr.reshape(image_array_smarr.shape[0], 344, 440, 3)\n",
        "print(image_array_smarr.shape, label_array_smarr.shape)"
      ],
      "metadata": {
        "id": "fl36hpjyJPCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write_tfrecords(image_array, label_array, \"./train.tfrecords\")\n",
        "\n",
        "write_tfrecords(image_array_smarr, label_array_smarr, \"./train_smote.tfrecords\")"
      ],
      "metadata": {
        "id": "hz-4RbvwdJNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train =read_dataset(10, 50, './train_smote.tfrecords')   # read_dataset(10, 50, './train.tfrecords')"
      ],
      "metadata": {
        "id": "qNijf1F-dKwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "LGWzPmQZdONK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_array = []\n",
        "# train_array = [\"CN_TRAIN_Image2D\", \"MCI_TRAIN_Image2D\", \"AD_TRAIN_Image2D\"]\n",
        "\n",
        "# for folder in train_array:\n",
        "#   for filename in os.listdir(folder):\n",
        "#     if filename.endswith('.npy'):\n",
        "#       label_array.append(0 if 'CN' in folder else 1 if 'MCI' in folder else 2)"
      ],
      "metadata": {
        "id": "-U26drO6dO1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_val_array = []\n",
        "label_val_array = []\n",
        "val_array = [\"CN_VAL_Image2D\", \"MCI_VAL_Image2D\", \"AD_VAL_Image2D\"]\n",
        "\n",
        "for folder in val_array:\n",
        "  for filename in os.listdir(folder):\n",
        "    if filename.endswith('.npy'):\n",
        "      image_val_array.append(np.load(f\"{folder}/{filename}\")) \n",
        "      label_val_array.append(0 if 'CN' in folder else 1 if 'MCI' in folder else 2)\n",
        "        \n",
        "image_val_array = np.array(image_val_array)"
      ],
      "metadata": {
        "id": "_NwZW56UdQ7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_val_array.shape)\n",
        "print(Counter(label_val_array).keys()) # equals to list(set(words))\n",
        "print(Counter(label_val_array).values()) # counts the elements' frequency"
      ],
      "metadata": {
        "id": "KuNbq5-EdWUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_tfrecords(image_val_array, label_val_array, \"./val.tfrecords\")"
      ],
      "metadata": {
        "id": "Es3o8pz7dYZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Validation = read_dataset(10, 50, './val.tfrecords') #image_val_array.shape[0]"
      ],
      "metadata": {
        "id": "LCAinNOHdan7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "aWuS1iLPdeGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_test_array = []\n",
        "label_test_array = []\n",
        "test_array = [\"CN_TEST_Image2D\", \"MCI_TEST_Image2D\", \"AD_TEST_Image2D\"]\n",
        "\n",
        "for folder in test_array:\n",
        "  for filename in os.listdir(folder):\n",
        "    if filename.endswith('.npy'):\n",
        "      image_test_array.append(np.load(f\"{folder}/{filename}\")) \n",
        "      label_test_array.append(0 if 'CN' in folder else 1 if 'MCI' in folder else 2)\n",
        "        \n",
        "image_test_array = np.array(image_test_array)"
      ],
      "metadata": {
        "id": "1wmbwFHKdgor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_test_array.shape)\n",
        "print(Counter(label_test_array).keys()) # equals to list(set(words))\n",
        "print(Counter(label_test_array).values())"
      ],
      "metadata": {
        "id": "nt3X7yIqdkkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_tfrecords(image_test_array, label_test_array, \"./test.tfrecords\")"
      ],
      "metadata": {
        "id": "fhVWDZcldmrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test = read_dataset(10, 50, './test.tfrecords')"
      ],
      "metadata": {
        "id": "QZ4tcqr2drUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "J3jnBOAPdtgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape=(344, 440, 3), \n",
        "    weights='imagenet', \n",
        "    include_top=False,  #\n",
        "    pooling='avg') #max\n",
        "base_model.trainable = False\n",
        "\n",
        "base_output = base_model.output\n",
        "hidden_layer = tf.keras.layers.Dense(512, activation='relu')(base_output) #512  #'relu'\n",
        "#hl_reg = tf.keras.layers.Dropout(0.5)(hidden_layer) #\n",
        "\n",
        "\n",
        "output_layer = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(hidden_layer)\n",
        "inception_model = tf.keras.models.Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# compile the model \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
        "METRICS = [\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "      tf.keras.metrics.AUC(name='prc', curve='PR'), #precision-recall curve\n",
        "      tf.keras.metrics.CategoricalAccuracy(name='categorical accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "\n",
        "]\n",
        "\n",
        "inception_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=METRICS)"
      ],
      "metadata": {
        "id": "E9rzf6F5duRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.summary()"
      ],
      "metadata": {
        "id": "Z3oy-f_HdySL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inception_model.fit(Train, epochs=2, validation_data=Validation, verbose=1)"
      ],
      "metadata": {
        "id": "vb4gTTusd1dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(patience=5, restore_best_weights=True) #, monitor='val_loss'\n",
        "history = inception_model.fit(Train, epochs=50, validation_data=Validation, verbose=1, callbacks=[es])"
      ],
      "metadata": {
        "id": "nECK1CxVd2A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.save(base_dir+'/inception_model2.h5')"
      ],
      "metadata": {
        "id": "pi91izfOd9ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.evaluate(Test)"
      ],
      "metadata": {
        "id": "limNcgtOeI4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(history):\n",
        "    with plt.style.context('seaborn-deep'):\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
        "        ## Plot Losses and Accuracies\n",
        "        x_axis = np.arange(len(history.history['loss']))\n",
        "        ax[0].set_title(\"Loss\")\n",
        "        ax[0].plot(x_axis, history.history['loss'], color=\"blue\", linestyle=\":\", marker=\"X\", label=\"Train Loss\")\n",
        "        ax[0].plot(x_axis, history.history['val_loss'], color=\"orange\", linestyle=\"-\", marker=\"X\", label=\"Val Loss\")\n",
        "        ax[1].set_title(\"AUC\")\n",
        "        ax[1].plot(x_axis, history.history['auc'], color=\"blue\", linestyle=\":\", marker=\"X\", label=\"Train AUC\")\n",
        "        ax[1].plot(x_axis,\n",
        "                   history.history['val_auc'],\n",
        "                   color=\"orange\",\n",
        "                   linestyle=\"-\",\n",
        "                   marker=\"X\",\n",
        "                   label=\"Val AUC\")\n",
        "        ax[2].set_title(\"PRC\")\n",
        "        ax[2].plot(x_axis, history.history['prc'], color=\"blue\", linestyle=\":\", marker=\"X\", label=\"Train PRC\")\n",
        "        ax[2].plot(x_axis,\n",
        "                   history.history['val_prc'],\n",
        "                   color=\"orange\",\n",
        "                   linestyle=\"-\",\n",
        "                   marker=\"X\",\n",
        "                   label=\"Val PRC\")\n",
        "        ## Customization\n",
        "        ax[0].grid(axis=\"x\", linewidth=0.5)\n",
        "        ax[0].grid(axis=\"y\", linewidth=0.5)\n",
        "        ax[0].legend()\n",
        "        ax[1].grid(axis=\"x\", linewidth=0.5)\n",
        "        ax[1].grid(axis=\"y\", linewidth=0.5)\n",
        "        ax[1].legend()\n",
        "        ax[2].grid(axis=\"x\", linewidth=0.5)\n",
        "        ax[2].grid(axis=\"y\", linewidth=0.5)\n",
        "        ax[2].legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "788y1kYNDZpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(history)"
      ],
      "metadata": {
        "id": "faGs3064E58g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = f\"./\"   \n",
        "Hdf5_files = []\n",
        "# r=root, d=directories, f = files\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.h5' in file:\n",
        "            Hdf5_files.append(os.path.join(r, file))"
      ],
      "metadata": {
        "id": "PfXG2sGDeThE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hdf5_files"
      ],
      "metadata": {
        "id": "n9wnfGTSeVrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "my_model = load_model(Hdf5_files[-1])"
      ],
      "metadata": {
        "id": "FK7zRW0lq9df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = my_model.predict(image_test_array)"
      ],
      "metadata": {
        "id": "0JP0tMxBrAY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "k5CY7EKpsWFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = []\n",
        "for prediction in predictions:\n",
        "  ypred.append(prediction.argmax())"
      ],
      "metadata": {
        "id": "2qYRi4_6rRrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(\n",
        "    label_test_array,\n",
        "    ypred\n",
        ")"
      ],
      "metadata": {
        "id": "WwJoTheCrwtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix"
      ],
      "metadata": {
        "id": "zjHatn5buX-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_df = pd.DataFrame(conf_matrix,\n",
        "                     index = ['CN','MCI','AD'], \n",
        "                     columns = ['CN','MCI','AD'])"
      ],
      "metadata": {
        "id": "UBNRXpKStxDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_df"
      ],
      "metadata": {
        "id": "aQFmtO0iuUGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_df, annot=True, cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actal Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bCqBvRwIuD7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_roc(label_test_array, predictions, title = 'ROC Plot');"
      ],
      "metadata": {
        "id": "iyVkQMKfzmRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_precision_recall(label_test_array, predictions, title = 'PR Curve');"
      ],
      "metadata": {
        "id": "0ixoTSTg1zdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fa-d1RWeL6ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['CN', 'MCI', 'AD']\n",
        "print(classification_report(label_test_array, ypred, target_names=target_names))"
      ],
      "metadata": {
        "id": "Fm-OihQ54ymZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= CREDENTIALS\n",
        "\n",
        "# Initialise a client\n",
        "client = storage.Client(PROJECT_NAME)\n",
        "# Create a bucket object for our bucket\n",
        "bucket = client.get_bucket(BUCKET_NAME)\n",
        "# Create a blob object from the filepath\n",
        "blob = bucket.blob('inception_trial.h5')\n",
        "# Upload the file to a destination\n",
        "blob.upload_from_filename('./inception_model1.h5')"
      ],
      "metadata": {
        "id": "2cBZPfSmeXSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wf9opXuv9cIO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}